# ------------------------------------------------------------------------------
# S-SVM (Support Vector Machine for Survival) ç”Ÿå­˜åˆ†ææ¨¡å‹
# åŸºäºVan Belle et al. (2011) "Support vector methods for survival analysis: a comparison between ranking and regression approaches"
# ------------------------------------------------------------------------------
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVR
from scipy.optimize import minimize
import pickle
import os
import warnings
warnings.filterwarnings('ignore')

class SSVMSurvival:
    def __init__(self, C=1.0, gamma='scale', kernel='rbf', epsilon=0.1, random_state=42):
        """
        S-SVMç”Ÿå­˜åˆ†ææ¨¡å‹
        
        å‚æ•°:
        C: æ­£åˆ™åŒ–å‚æ•°
        gamma: RBFæ ¸å‚æ•°
        kernel: æ ¸å‡½æ•°ç±»å‹ ('rbf', 'linear', 'poly', 'sigmoid')
        epsilon: SVRçš„epsilonå‚æ•°
        random_state: éšæœºç§å­
        """
        self.C = C
        self.gamma = gamma
        self.kernel = kernel
        self.epsilon = epsilon
        self.random_state = random_state
        self.model = None
        self.scaler = StandardScaler()
        self.feature_selector = None
        
    def load_data(self, csv_path):
        """åŠ è½½CSVæ•°æ®"""
        print("æ­£åœ¨åŠ è½½æ•°æ®...")
        df = pd.read_csv(csv_path)
        
        # æ•°æ®é¢„å¤„ç†
        X = df.iloc[:, 3:].values.astype(np.float32)  # ç‰¹å¾
        e = df.iloc[:, 1].values.astype(bool)         # äº‹ä»¶æŒ‡ç¤º
        # t = np.round(df.iloc[:, 2].values).astype(np.int32)
        t = np.round(df.iloc[:, 2].values, 2).astype(np.float32)  # æ—¶é—´ä¿ç•™ä¸¤ä½å°æ•°
        
        # è·å–ç‰¹å¾å
        feature_names = df.columns[3:].tolist()
        
        # # è¿‡æ»¤æ— æ•ˆçš„æ—¶é—´å€¼ï¼ˆ<=0çš„æ—¶é—´ï¼‰
        # valid_mask = t > 0
        # if not np.all(valid_mask):
        #     print(f"å‘ç° {np.sum(~valid_mask)} ä¸ªæ— æ•ˆæ—¶é—´å€¼ï¼ˆ<=0ï¼‰ï¼Œå°†è¢«è¿‡æ»¤æ‰")
        #     X = X[valid_mask]
        #     e = e[valid_mask]
        #     t = t[valid_mask]
        
        # å¤„ç†ç¼ºå¤±å€¼
        if np.any(np.isnan(X)):
            print("å¤„ç†ç¼ºå¤±å€¼...")
            X = pd.DataFrame(X).fillna(pd.DataFrame(X).mean()).values
        
        print(f"æ•°æ®å½¢çŠ¶: {X.shape}")
        print(f"äº‹ä»¶å‘ç”Ÿæ•°: {np.sum(e)}")
        print(f"åˆ å¤±æ•°: {np.sum(~e)}")
        print(f"æ—¶é—´èŒƒå›´: {np.min(t):.2f} - {np.max(t):.2f}")
        
        return X, e, t, feature_names
    
    def _create_survival_target(self, t, e):
        """
        åˆ›å»ºS-SVMçš„ç›®æ ‡å˜é‡
        å¯¹äºåˆ å¤±æ ·æœ¬ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç§ç‰¹æ®Šçš„ç¼–ç æ–¹å¼
        """
        # æ–¹æ³•1: ç›´æ¥ä½¿ç”¨è§‚å¯Ÿæ—¶é—´ï¼Œä½†å¯¹åˆ å¤±æ ·æœ¬è¿›è¡Œè°ƒæ•´
        target = t.copy()
        
        # å¯¹åˆ å¤±æ ·æœ¬ï¼Œæˆ‘ä»¬å‡è®¾çœŸå®ç”Ÿå­˜æ—¶é—´å¤§äºè§‚å¯Ÿæ—¶é—´
        # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªå¯å‘å¼æ–¹æ³•ï¼šå°†åˆ å¤±æ ·æœ¬çš„ç›®æ ‡æ—¶é—´è®¾ä¸ºè§‚å¯Ÿæ—¶é—´çš„1.5å€
        censored_mask = ~e
        if np.any(censored_mask):
            max_observed_time = np.max(t[e])  # æœ€å¤§çš„äº‹ä»¶å‘ç”Ÿæ—¶é—´
            target[censored_mask] = np.maximum(
                t[censored_mask] * 1.2,  # è‡³å°‘æ˜¯è§‚å¯Ÿæ—¶é—´çš„1.2å€
                t[censored_mask] + 0.5   # æˆ–è€…è§‚å¯Ÿæ—¶é—´åŠ 0.5å¹´
            )
            # ä½†ä¸èƒ½è¶…è¿‡æœ€å¤§è§‚å¯Ÿæ—¶é—´çš„2å€
            target[censored_mask] = np.minimum(target[censored_mask], max_observed_time * 2)
        
        return target
    
    def _concordance_index(self, risk_scores, t, e):
        """è®¡ç®—C-index"""
        n = len(risk_scores)
        concordant = 0
        total_pairs = 0
        
        for i in range(n):
            for j in range(i+1, n):
                # åªè€ƒè™‘å¯æ¯”è¾ƒçš„å¯¹
                if e[i] and t[i] <= t[j]:
                    # iå‘ç”Ÿäº‹ä»¶ä¸”æ—¶é—´è¾ƒæ—©ï¼Œåº”è¯¥æœ‰æ›´é«˜çš„é£é™©åˆ†æ•°
                    total_pairs += 1
                    if risk_scores[i] > risk_scores[j]:
                        concordant += 1
                elif e[j] and t[j] <= t[i]:
                    # jå‘ç”Ÿäº‹ä»¶ä¸”æ—¶é—´è¾ƒæ—©ï¼Œåº”è¯¥æœ‰æ›´é«˜çš„é£é™©åˆ†æ•°
                    total_pairs += 1
                    if risk_scores[j] > risk_scores[i]:
                        concordant += 1
        
        if total_pairs == 0:
            return 0.5
        
        return concordant / total_pairs
    
    def feature_selection(self, X, t, k_features=20):
        """ç‰¹å¾é€‰æ‹©"""
        if X.shape[1] <= k_features:
            print(f"ç‰¹å¾æ•°é‡({X.shape[1]})å°äºç­‰äºç›®æ ‡æ•°é‡({k_features})ï¼Œè·³è¿‡ç‰¹å¾é€‰æ‹©")
            return X, list(range(X.shape[1]))
        
        print(f"\nè¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œé€‰æ‹©å‰{k_features}ä¸ªæœ€é‡è¦çš„ç‰¹å¾...")
        
        # ä½¿ç”¨ç”Ÿå­˜æ—¶é—´ä½œä¸ºç›®æ ‡è¿›è¡Œç‰¹å¾é€‰æ‹©
        self.feature_selector = SelectKBest(score_func=f_regression, k=k_features)
        X_selected = self.feature_selector.fit_transform(X, t)
        
        # è·å–é€‰æ‹©çš„ç‰¹å¾ç´¢å¼•
        selected_indices = self.feature_selector.get_support(indices=True)
        
        print(f"é€‰æ‹©çš„ç‰¹å¾ç´¢å¼•: {selected_indices}")
        
        return X_selected, selected_indices
    
    def train(self, X, e, t, test_size=0.3, feature_selection=True, k_features=20):
        """è®­ç»ƒS-SVMç”Ÿå­˜æ¨¡å‹"""
        print("\nå¼€å§‹è®­ç»ƒS-SVMç”Ÿå­˜æ¨¡å‹...")
        
        # ç‰¹å¾é€‰æ‹©
        if feature_selection:
            X, selected_indices = self.feature_selection(X, t, k_features)
        else:
            selected_indices = list(range(X.shape[1]))
        
        # åˆ›å»ºç”Ÿå­˜ç›®æ ‡å˜é‡
        survival_target = self._create_survival_target(t, e)
        
        # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, e_train, e_test, t_train, t_test, target_train, target_test = train_test_split(
            X, e, t, survival_target, test_size=test_size, random_state=self.random_state, stratify=e
        )
        
        print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}")
        print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape[0]}")
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # è®­ç»ƒSVRæ¨¡å‹
        self.model = SVR(
            C=self.C,
            gamma=self.gamma,
            kernel=self.kernel,
            epsilon=self.epsilon
        )
        
        print(f"ä½¿ç”¨å‚æ•°: C={self.C}, gamma={self.gamma}, kernel={self.kernel}, epsilon={self.epsilon}")
        
        # æ‹Ÿåˆæ¨¡å‹
        self.model.fit(X_train_scaled, target_train)
        
        # é¢„æµ‹ç”Ÿå­˜æ—¶é—´
        pred_train = self.model.predict(X_train_scaled)
        pred_test = self.model.predict(X_test_scaled)
        
        # å°†é¢„æµ‹çš„ç”Ÿå­˜æ—¶é—´è½¬æ¢ä¸ºé£é™©åˆ†æ•°ï¼ˆç”Ÿå­˜æ—¶é—´è¶ŠçŸ­ï¼Œé£é™©è¶Šé«˜ï¼‰
        risk_scores_train = -pred_train  # è´Ÿå·ï¼šæ—¶é—´è¶ŠçŸ­é£é™©è¶Šé«˜
        risk_scores_test = -pred_test
        
        # è®¡ç®—C-index
        train_c_index = self._concordance_index(risk_scores_train, t_train, e_train)
        test_c_index = self._concordance_index(risk_scores_test, t_test, e_test)
        
        # è®¡ç®—å›å½’æ€§èƒ½æŒ‡æ ‡
        train_mse = mean_squared_error(target_train, pred_train)
        test_mse = mean_squared_error(target_test, pred_test)
        
        print(f"è®­ç»ƒé›† - C-index: {train_c_index:.4f}, MSE: {train_mse:.4f}")
        print(f"æµ‹è¯•é›† - C-index: {test_c_index:.4f}, MSE: {test_mse:.4f}")
        
        # å­˜å‚¨ç»“æœ
        self.results = {
            'train_c_index': train_c_index,
            'test_c_index': test_c_index,
            'train_mse': train_mse,
            'test_mse': test_mse,
            'X_train': X_train_scaled,
            'X_test': X_test_scaled,
            'e_train': e_train,
            'e_test': e_test,
            't_train': t_train,
            't_test': t_test,
            'selected_indices': selected_indices,
            'pred_train': pred_train,
            'pred_test': pred_test,
            'risk_scores_train': risk_scores_train,
            'risk_scores_test': risk_scores_test
        }
        
        # ä¿å­˜æ¨¡å‹
        self.save_model()
        
        return test_c_index
    
    def hyperparameter_tuning(self, X, e, t, cv_folds=3):
        """è¶…å‚æ•°è°ƒä¼˜"""
        print("\nå¼€å§‹è¶…å‚æ•°è°ƒä¼˜...")
        
        # ç‰¹å¾é€‰æ‹©å’Œæ ‡å‡†åŒ–
        if X.shape[1] > 20:
            X, _ = self.feature_selection(X, t, 20)
        
        survival_target = self._create_survival_target(t, e)
        X_scaled = self.scaler.fit_transform(X)
        
        # å®šä¹‰å‚æ•°ç½‘æ ¼
        param_grid = {
            'C': [0.1, 1.0, 10.0, 100.0],
            'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1.0],
            'epsilon': [0.01, 0.1, 0.2, 0.5],
            'kernel': ['rbf', 'linear']
        }
        
        best_score = -np.inf
        best_params = None
        
        # ç®€åŒ–çš„ç½‘æ ¼æœç´¢
        print("æ­£åœ¨æœç´¢æœ€ä½³å‚æ•°ç»„åˆ...")
        total_combinations = len(param_grid['C']) * len(param_grid['gamma']) * len(param_grid['epsilon']) * len(param_grid['kernel'])
        current_combination = 0
        
        for C in param_grid['C']:
            for gamma in param_grid['gamma']:
                for epsilon in param_grid['epsilon']:
                    for kernel in param_grid['kernel']:
                        current_combination += 1
                        print(f"è¿›åº¦: {current_combination}/{total_combinations} - æµ‹è¯•å‚æ•°: C={C}, gamma={gamma}, epsilon={epsilon}, kernel={kernel}")
                        
                        try:
                            model = SVR(C=C, gamma=gamma, epsilon=epsilon, kernel=kernel)
                            model.fit(X_scaled, survival_target)
                            
                            # é¢„æµ‹å¹¶è®¡ç®—C-index
                            pred = model.predict(X_scaled)
                            risk_scores = -pred
                            c_index = self._concordance_index(risk_scores, t, e)
                            
                            if c_index > best_score:
                                best_score = c_index
                                best_params = {
                                    'C': C, 
                                    'gamma': gamma, 
                                    'epsilon': epsilon, 
                                    'kernel': kernel
                                }
                                print(f"  âœ“ æ–°çš„æœ€ä½³å‚æ•°! C-index: {c_index:.4f}")
                            else:
                                print(f"  C-index: {c_index:.4f}")
                                
                        except Exception as e:
                            print(f"  âœ— å‚æ•°ç»„åˆå¤±è´¥: {e}")
                            continue
        
        print(f"\næœ€ä½³å‚æ•°: {best_params}")
        print(f"æœ€ä½³ C-index: {best_score:.4f}")
        
        return best_params
    
    def plot_predictions(self):
        """ç»˜åˆ¶é¢„æµ‹ç»“æœ"""
        if self.model is None:
            print("è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # é¢„æµ‹æ—¶é—´ vs å®é™…æ—¶é—´
        axes[0, 0].scatter(self.results['t_train'], self.results['pred_train'], 
                          alpha=0.6, label='è®­ç»ƒé›†', color='blue')
        axes[0, 0].scatter(self.results['t_test'], self.results['pred_test'], 
                          alpha=0.6, label='æµ‹è¯•é›†', color='red')
        
        # æ·»åŠ å¯¹è§’çº¿
        min_time = min(np.min(self.results['t_train']), np.min(self.results['t_test']))
        max_time = max(np.max(self.results['pred_train']), np.max(self.results['pred_test']))
        axes[0, 0].plot([min_time, max_time], [min_time, max_time], 'k--', alpha=0.7)
        
        axes[0, 0].set_xlabel('å®é™…ç”Ÿå­˜æ—¶é—´')
        axes[0, 0].set_ylabel('é¢„æµ‹ç”Ÿå­˜æ—¶é—´')
        axes[0, 0].set_title('é¢„æµ‹æ—¶é—´ vs å®é™…æ—¶é—´')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # é£é™©åˆ†æ•°åˆ†å¸ƒ
        axes[0, 1].hist(self.results['risk_scores_train'], bins=30, alpha=0.7, 
                       label='è®­ç»ƒé›†', color='blue', density=True)
        axes[0, 1].hist(self.results['risk_scores_test'], bins=30, alpha=0.7, 
                       label='æµ‹è¯•é›†', color='red', density=True)
        axes[0, 1].set_xlabel('é£é™©åˆ†æ•°')
        axes[0, 1].set_ylabel('å¯†åº¦')
        axes[0, 1].set_title('é£é™©åˆ†æ•°åˆ†å¸ƒ')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # äº‹ä»¶å‘ç”Ÿ vs é£é™©åˆ†æ•°
        event_mask = self.results['e_test']
        censored_mask = ~self.results['e_test']
        
        axes[1, 0].scatter(self.results['risk_scores_test'][event_mask], 
                          self.results['t_test'][event_mask],
                          c='red', alpha=0.6, label='äº‹ä»¶å‘ç”Ÿ', marker='o')
        axes[1, 0].scatter(self.results['risk_scores_test'][censored_mask], 
                          self.results['t_test'][censored_mask],
                          c='blue', alpha=0.6, label='åˆ å¤±', marker='^')
        axes[1, 0].set_xlabel('é£é™©åˆ†æ•°')
        axes[1, 0].set_ylabel('è§‚å¯Ÿæ—¶é—´')
        axes[1, 0].set_title('é£é™©åˆ†æ•° vs è§‚å¯Ÿæ—¶é—´')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # æ®‹å·®åˆ†æ
        residuals_train = self.results['pred_train'] - self.results['t_train']
        residuals_test = self.results['pred_test'] - self.results['t_test']
        
        axes[1, 1].scatter(self.results['pred_train'], residuals_train, 
                          alpha=0.6, label='è®­ç»ƒé›†', color='blue')
        axes[1, 1].scatter(self.results['pred_test'], residuals_test, 
                          alpha=0.6, label='æµ‹è¯•é›†', color='red')
        axes[1, 1].axhline(y=0, color='k', linestyle='--', alpha=0.7)
        axes[1, 1].set_xlabel('é¢„æµ‹å€¼')
        axes[1, 1].set_ylabel('æ®‹å·®')
        axes[1, 1].set_title('æ®‹å·®åˆ†æ')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('s_svm_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def save_model(self, save_path='logs/models/s_svm.pkl'):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if self.model is None:
            print("æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹å¯ä»¥ä¿å­˜ï¼")
            return
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹å’Œç›¸å…³ç»„ä»¶
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'feature_selector': self.feature_selector,
            'results': self.results,
            'hyperparameters': {
                'C': self.C,
                'gamma': self.gamma,
                'kernel': self.kernel,
                'epsilon': self.epsilon,
                'random_state': self.random_state
            }
        }
        
        with open(save_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"\nğŸ’¾ S-SVMæ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_model(self, load_path='logs/models/s_svm.pkl'):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if not os.path.exists(load_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {load_path}")
            return False
        
        try:
            with open(load_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.feature_selector = model_data.get('feature_selector')
            self.results = model_data.get('results', {})
            
            # æ¢å¤è¶…å‚æ•°
            hyperparams = model_data.get('hyperparameters', {})
            self.C = hyperparams.get('C', self.C)
            self.gamma = hyperparams.get('gamma', self.gamma)
            self.kernel = hyperparams.get('kernel', self.kernel)
            self.epsilon = hyperparams.get('epsilon', self.epsilon)
            self.random_state = hyperparams.get('random_state', self.random_state)
            
            print(f"âœ… S-SVMæ¨¡å‹å·²ä» {load_path} åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def predict(self, X):
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        if self.model is None:
            print("âŒ æ¨¡å‹æœªè®­ç»ƒæˆ–æœªåŠ è½½ï¼")
            return None
        
        try:
            # ç‰¹å¾é€‰æ‹©ï¼ˆå¦‚æœä¹‹å‰è¿›è¡Œè¿‡ï¼‰
            if self.feature_selector is not None:
                X_selected = self.feature_selector.transform(X)
            else:
                X_selected = X
            
            # ç‰¹å¾æ ‡å‡†åŒ–
            X_scaled = self.scaler.transform(X_selected)
            
            # é¢„æµ‹ç”Ÿå­˜æ—¶é—´
            pred_times = self.model.predict(X_scaled)
            
            # è½¬æ¢ä¸ºé£é™©åˆ†æ•°
            risk_scores = -pred_times
            
            return risk_scores
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def print_model_summary(self):
        """æ‰“å°æ¨¡å‹æ‘˜è¦"""
        if self.model is None:
            print("è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼")
            return
        
        print("\n" + "="*50)
        print("S-SVM æ¨¡å‹æ‘˜è¦")
        print("="*50)
        print(f"æ ¸å‡½æ•°: {self.model.kernel}")
        print(f"Cå‚æ•°: {self.model.C}")
        print(f"Gammaå‚æ•°: {self.model.gamma}")
        print(f"Epsilonå‚æ•°: {self.model.epsilon}")
        print(f"æ”¯æŒå‘é‡æ•°é‡: {len(self.model.support_vectors_)}")
        print(f"æ”¯æŒå‘é‡æ¯”ä¾‹: {len(self.model.support_vectors_) / len(self.results['X_train']):.2%}")
        
        print(f"\næ€§èƒ½æŒ‡æ ‡:")
        print(f"è®­ç»ƒé›† C-index: {self.results['train_c_index']:.4f}")
        print(f"æµ‹è¯•é›† C-index: {self.results['test_c_index']:.4f}")
        print(f"è®­ç»ƒé›† MSE: {self.results['train_mse']:.4f}")
        print(f"æµ‹è¯•é›† MSE: {self.results['test_mse']:.4f}")

def main():
    # æ•°æ®è·¯å¾„
    csv_path = ''
    model_path = 'logs/"models/s_svm.pkl'
    
    # åˆ›å»ºæ¨¡å‹
    ssvm_model = SSVMSurvival(C=10.0, gamma='scale', kernel='rbf', epsilon=0.1, random_state=42)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
    if os.path.exists(model_path):
        print(f"ğŸ” å‘ç°å·²è®­ç»ƒçš„æ¨¡å‹: {model_path}")
        choice = input("æ˜¯å¦ä½¿ç”¨å·²æœ‰æ¨¡å‹ï¼Ÿ(y/n): ").lower()
        
        if choice == 'y':
            if ssvm_model.load_model(model_path):
                print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè·³è¿‡è®­ç»ƒæ­¥éª¤")
                ssvm_model.print_model_summary()
                return ssvm_model
            else:
                print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°†é‡æ–°è®­ç»ƒ")
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹...")
    
    # åŠ è½½æ•°æ®
    X, e, t, feature_names = ssvm_model.load_data(csv_path)
    
    # è®­ç»ƒæ¨¡å‹
    test_c_index = ssvm_model.train(X, e, t, feature_selection=True, k_features=20)
    
    # æ‰“å°æ¨¡å‹æ‘˜è¦
    ssvm_model.print_model_summary()
    
    # è¶…å‚æ•°è°ƒä¼˜ï¼ˆå¯é€‰ï¼Œæ¯”è¾ƒè€—æ—¶ï¼‰
    print("\næ˜¯å¦è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜ï¼Ÿè¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")
    # best_params = ssvm_model.hyperparameter_tuning(X, e, t)
    
    # ç»˜åˆ¶åˆ†æå›¾
    ssvm_model.plot_predictions()
    
    print(f"\n=== S-SVM ç”Ÿå­˜åˆ†æç»“æœ ===")
    print(f"æœ€ç»ˆæµ‹è¯•é›† C-index: {test_c_index:.4f}")
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ï¼Œåç»­å¯ç›´æ¥åŠ è½½ä½¿ç”¨")
    
    return ssvm_model

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½...")
    
    # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
    test_model = SSVMSurvival()
    
    # åŠ è½½æ¨¡å‹
    if test_model.load_model():
        print("âœ… æ¨¡å‹åŠ è½½æµ‹è¯•æˆåŠŸ")
        test_model.print_model_summary()
        
        # æµ‹è¯•é¢„æµ‹åŠŸèƒ½ï¼ˆä½¿ç”¨ä¸€äº›ç¤ºä¾‹æ•°æ®ï¼‰
        csv_path = r""
        X, e, t, _ = test_model.load_data(csv_path)
        
        # ä½¿ç”¨å‰5ä¸ªæ ·æœ¬æµ‹è¯•é¢„æµ‹
        test_X = X[:5]
        predictions = test_model.predict(test_X)
        
        if predictions is not None:
            print(f"\nğŸ¯ é¢„æµ‹æµ‹è¯•æˆåŠŸï¼Œå‰5ä¸ªæ ·æœ¬çš„é£é™©åˆ†æ•°: {predictions}")
        else:
            print("âŒ é¢„æµ‹æµ‹è¯•å¤±è´¥")
    else:
        print("âŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥")

if __name__ == '__main__':
    model = main()
    
    # å¯é€‰ï¼šæµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½
    # test_model_loading()
