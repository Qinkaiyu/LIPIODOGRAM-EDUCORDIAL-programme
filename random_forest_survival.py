# ------------------------------------------------------------------------------
# Random Forest ç”Ÿå­˜åˆ†ææ¨¡å‹
# ------------------------------------------------------------------------------
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import ParameterSampler
from scipy.stats import randint, uniform
from sksurv.ensemble import RandomSurvivalForest
from sksurv.metrics import concordance_index_censored
from sksurv.util import Surv
import pickle
import os
import warnings
warnings.filterwarnings('ignore')

class RandomForestSurvival:
    def __init__(self, n_estimators=100, max_depth=None, random_state=42):
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.random_state = random_state
        self.model = None
        
    def load_data(self, csv_path):
        """åŠ è½½CSVæ•°æ®"""
        print("æ­£åœ¨åŠ è½½æ•°æ®...")
        df = pd.read_csv(csv_path)
        
        # æ•°æ®é¢„å¤„ç†
        X = df.iloc[:, 3:].values.astype(np.float32)  # ç‰¹å¾
        e = df.iloc[:, 1].values.astype(bool)         # äº‹ä»¶æŒ‡ç¤º
        t = np.round(df.iloc[:, 2].values, 2).astype(np.float32)  # æ—¶é—´ä¿ç•™ä¸¤ä½å°æ•°
        
        # # è¿‡æ»¤æ— æ•ˆçš„æ—¶é—´å€¼ï¼ˆ<=0çš„æ—¶é—´ï¼‰
        # valid_mask = t > 0
        # if not np.all(valid_mask):
        #     print(f"å‘ç° {np.sum(~valid_mask)} ä¸ªæ— æ•ˆæ—¶é—´å€¼ï¼ˆ<=0ï¼‰ï¼Œå°†è¢«è¿‡æ»¤æ‰")
        #     X = X[valid_mask]
        #     e = e[valid_mask]
        #     t = t[valid_mask]
        
        # å¤„ç†ç¼ºå¤±å€¼
        if np.any(np.isnan(X)):
            print("å¤„ç†ç¼ºå¤±å€¼...")
            X = pd.DataFrame(X).fillna(pd.DataFrame(X).mean()).values
        
        print(f"æ•°æ®å½¢çŠ¶: {X.shape}")
        print(f"äº‹ä»¶å‘ç”Ÿæ•°: {np.sum(e)}")
        print(f"åˆ å¤±æ•°: {np.sum(~e)}")
        print(f"æ—¶é—´èŒƒå›´: {np.min(t):.2f} - {np.max(t):.2f}")
        
        return X, e, t
    
    def train(self, X, e, t, test_size=0.3):
        """è®­ç»ƒRandom Forestç”Ÿå­˜æ¨¡å‹"""
        print("\nå¼€å§‹è®­ç»ƒRandom Forestç”Ÿå­˜æ¨¡å‹...")
        
        # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, e_train, e_test, t_train, t_test = train_test_split(
            X, e, t, test_size=test_size, random_state=self.random_state, stratify=e
        )
        
        # åˆ›å»ºç”Ÿå­˜æ•°æ®ç»“æ„
        y_train = Surv.from_arrays(e_train, t_train)
        y_test = Surv.from_arrays(e_test, t_test)
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = RandomSurvivalForest(
            n_estimators=self.n_estimators,
            max_depth=self.max_depth,
            random_state=self.random_state,
            n_jobs=-1
        )
        
        # è®­ç»ƒæ¨¡å‹
        self.model.fit(X_train, y_train)
        
        # é¢„æµ‹
        risk_scores_train = self.model.predict(X_train)
        risk_scores_test = self.model.predict(X_test)
        
        # è®¡ç®—C-index
        train_c_index = concordance_index_censored(e_train, t_train, risk_scores_train)[0]
        test_c_index = concordance_index_censored(e_test, t_test, risk_scores_test)[0]
        
        print(f"è®­ç»ƒé›† C-index: {train_c_index:.4f}")
        print(f"æµ‹è¯•é›† C-index: {test_c_index:.4f}")
        
        # å­˜å‚¨ç»“æœ
        self.results = {
            'train_c_index': train_c_index,
            'test_c_index': test_c_index,
            'X_train': X_train,
            'X_test': X_test,
            'y_train': y_train,
            'y_test': y_test,
            'risk_scores_train': risk_scores_train,
            'risk_scores_test': risk_scores_test
        }
        
        # ä¿å­˜æ¨¡å‹
        self.save_model()
        
        return test_c_index
    
    def hyperparameter_tuning(self, X, e, t):
        """è¶…å‚æ•°è°ƒä¼˜"""
        print("\nå¼€å§‹è¶…å‚æ•°è°ƒä¼˜...")
        
        # åˆ’åˆ†æ•°æ®
        X_train, X_test, e_train, e_test, t_train, t_test = train_test_split(
            X, e, t, test_size=0.3, random_state=self.random_state, stratify=e
        )
        
        y_train = Surv.from_arrays(e_train, t_train)
        
        # å®šä¹‰å‚æ•°ç½‘æ ¼
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [3, 5, 10, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        
        # ç½‘æ ¼æœç´¢
        rf = RandomSurvivalForest(random_state=self.random_state, n_jobs=-1)
        
        best_score = -np.inf
        best_params = None
        
        # ç®€åŒ–çš„ç½‘æ ¼æœç´¢ï¼ˆç”±äºsksurvä¸ç›´æ¥æ”¯æŒGridSearchCVï¼‰
        for n_est in param_grid['n_estimators']:
            for max_d in param_grid['max_depth']:
                for min_split in param_grid['min_samples_split']:
                    for min_leaf in param_grid['min_samples_leaf']:
                        try:
                            model = RandomSurvivalForest(
                                n_estimators=n_est,
                                max_depth=max_d,
                                min_samples_split=min_split,
                                min_samples_leaf=min_leaf,
                                random_state=self.random_state,
                                n_jobs=-1
                            )
                            model.fit(X_train, y_train)
                            
                            # ä½¿ç”¨OOB scoreä½œä¸ºè¯„ä¼°æŒ‡æ ‡
                            if hasattr(model, 'oob_score_') and model.oob_score_ > best_score:
                                best_score = model.oob_score_
                                best_params = {
                                    'n_estimators': n_est,
                                    'max_depth': max_d,
                                    'min_samples_split': min_split,
                                    'min_samples_leaf': min_leaf
                                }
                        except:
                            continue
        
        print(f"æœ€ä½³å‚æ•°: {best_params}")
        print(f"æœ€ä½³å¾—åˆ†: {best_score:.4f}")
        
        return best_params
    
    def save_model(self, save_path='logs/models/random_forest2.pkl'):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if self.model is None:
            print("æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹å¯ä»¥ä¿å­˜ï¼")
            return
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        # ç¡®å®šæ¨¡å‹ç±»å‹
        model_type = 'survival' if hasattr(self.model, 'predict') and 'RandomSurvival' in str(type(self.model)) else 'regression'
        
        # ä¿å­˜æ¨¡å‹å’Œç›¸å…³ç»„ä»¶
        model_data = {
            'model': self.model,
            'type': model_type,
            'results': self.results,
            'hyperparameters': {
                'n_estimators': self.n_estimators,
                'max_depth': self.max_depth,
                'random_state': self.random_state
            }
        }
        
        with open(save_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"\nğŸ’¾ Random Forestæ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_model(self, load_path='logs/models/random_forest2.pkl'):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if not os.path.exists(load_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {load_path}")
            return False
        
        try:
            with open(load_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model = model_data['model']
            self.model_type = model_data.get('type', 'survival')
            self.results = model_data.get('results', {})
            
            # æ¢å¤è¶…å‚æ•°
            hyperparams = model_data.get('hyperparameters', {})
            self.n_estimators = hyperparams.get('n_estimators', self.n_estimators)
            self.max_depth = hyperparams.get('max_depth', self.max_depth)
            self.random_state = hyperparams.get('random_state', self.random_state)
            
            print(f"âœ… Random Forestæ¨¡å‹å·²ä» {load_path} åŠ è½½æˆåŠŸ")
            print(f"   æ¨¡å‹ç±»å‹: {self.model_type}")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def predict(self, X):
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        if self.model is None:
            print("âŒ æ¨¡å‹æœªè®­ç»ƒæˆ–æœªåŠ è½½ï¼")
            return None
        
        try:
            if hasattr(self, 'model_type') and self.model_type == 'regression':
                # å›å½’æ¨¡å‹ï¼šé¢„æµ‹æ—¶é—´ï¼Œç„¶åè½¬æ¢ä¸ºé£é™©åˆ†æ•°
                pred_times = self.model.predict(X)
                risk_scores = -pred_times
            else:
                # ç”Ÿå­˜åˆ†ææ¨¡å‹ï¼šç›´æ¥é¢„æµ‹é£é™©åˆ†æ•°
                risk_scores = self.model.predict(X)
            
            return risk_scores
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    # def plot_feature_importance(self, feature_names=None):
    #     """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§"""
    #     if self.model is None:
    #         print("è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼")
    #         return
        
    #     importance = self.model.feature_importances_
        
    #     if feature_names is None:
    #         feature_names = [f'Feature_{i}' for i in range(len(importance))]
        
    #     # æ’åº
    #     indices = np.argsort(importance)[::-1]
        
    #     plt.figure(figsize=(12, 8))
    #     plt.title("Random Forest ç‰¹å¾é‡è¦æ€§")
    #     plt.bar(range(len(importance)), importance[indices])
    #     plt.xticks(range(len(importance)), [feature_names[i] for i in indices], rotation=45)
    #     plt.tight_layout()
    #     plt.savefig('rf_feature_importance.png', dpi=300, bbox_inches='tight')
    #     plt.show()
        
    #     # æ‰“å°å‰10ä¸ªé‡è¦ç‰¹å¾
    #     print("\nå‰10ä¸ªæœ€é‡è¦çš„ç‰¹å¾:")
    #     for i in range(min(10, len(importance))):
    #         idx = indices[i]
    #         print(f"{feature_names[idx]}: {importance[idx]:.4f}")

def main():
    # æ•°æ®è·¯å¾„
    csv_path = ""
    model_path = 'logs/models/random_forest.pkl'
    
    # åˆ›å»ºæ¨¡å‹
    rf_model = RandomForestSurvival(n_estimators=350, max_depth=7, random_state=42)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
    if os.path.exists(model_path):
        print(f"ğŸ” å‘ç°å·²è®­ç»ƒçš„æ¨¡å‹: {model_path}")
        choice = input("æ˜¯å¦ä½¿ç”¨å·²æœ‰æ¨¡å‹ï¼Ÿ(y/n): ").lower()
        
        if choice == 'y':
            if rf_model.load_model(model_path):
                print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè·³è¿‡è®­ç»ƒæ­¥éª¤")
                # æ‰“å°æ¨¡å‹ä¿¡æ¯
                if rf_model.results:
                    print(f"è®­ç»ƒé›† C-index: {rf_model.results.get('train_c_index', 'N/A'):.4f}")
                    print(f"æµ‹è¯•é›† C-index: {rf_model.results.get('test_c_index', 'N/A'):.4f}")
                return rf_model
            else:
                print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°†é‡æ–°è®­ç»ƒ")
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹...")
    
    # åŠ è½½æ•°æ®
    X, e, t = rf_model.load_data(csv_path)
    
    # è®­ç»ƒæ¨¡å‹
    test_c_index = rf_model.train(X, e, t)
    
    # è¶…å‚æ•°è°ƒä¼˜ï¼ˆå¯é€‰ï¼Œæ¯”è¾ƒè€—æ—¶ï¼‰
    # print("\næ˜¯å¦è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜ï¼Ÿè¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")
    # best_params = rf_model.hyperparameter_tuning(X, e, t)
    
    # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
    #rf_model.plot_feature_importance()
    
    print(f"\n=== Random Forest ç”Ÿå­˜åˆ†æç»“æœ ===")
    print(f"æœ€ç»ˆæµ‹è¯•é›† C-index: {test_c_index:.4f}")
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ï¼Œåç»­å¯ç›´æ¥åŠ è½½ä½¿ç”¨")
    
    return rf_model

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•Random Forestæ¨¡å‹åŠ è½½åŠŸèƒ½...")
    
    # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
    test_model = RandomForestSurvival()
    
    # åŠ è½½æ¨¡å‹
    if test_model.load_model():
        print("âœ… æ¨¡å‹åŠ è½½æµ‹è¯•æˆåŠŸ")
        
        # æµ‹è¯•é¢„æµ‹åŠŸèƒ½ï¼ˆä½¿ç”¨ä¸€äº›ç¤ºä¾‹æ•°æ®ï¼‰
        csv_path = r"C:/Users/yuqinkai/Downloads/Smaple_LIP_copy.csv"
        X, e, t = test_model.load_data(csv_path)
        
        # ä½¿ç”¨å‰5ä¸ªæ ·æœ¬æµ‹è¯•é¢„æµ‹
        test_X = X[:5]
        predictions = test_model.predict(test_X)
        
        if predictions is not None:
            print(f"\nğŸ¯ é¢„æµ‹æµ‹è¯•æˆåŠŸï¼Œå‰5ä¸ªæ ·æœ¬çš„é£é™©åˆ†æ•°: {predictions}")
        else:
            print("âŒ é¢„æµ‹æµ‹è¯•å¤±è´¥")
    else:
        print("âŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥")

if __name__ == '__main__':
    model = main()
    
    # å¯é€‰ï¼šæµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½
    # test_model_loading()
